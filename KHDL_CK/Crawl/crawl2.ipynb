{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Starting watch scraping program as of 05/21/24 23:03:44 with max_threading_workers=25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Found 124 pages to scrape from https://www.chrono24.com/\n",
      "INFO:__main__:Scraping page 1\n",
      "INFO:__main__:Scraping page 2\n",
      "INFO:__main__:Scraping page 3\n",
      "INFO:__main__:Scraping page 4\n",
      "INFO:__main__:Scraping page 5\n",
      "INFO:__main__:Scraping page 6\n",
      "INFO:__main__:Scraping page 7\n",
      "INFO:__main__:Scraping page 8\n",
      "INFO:__main__:Scraping page 9\n",
      "INFO:__main__:Scraping page 10\n",
      "INFO:__main__:Scraping page 11\n",
      "INFO:__main__:Scraping page 12\n",
      "INFO:__main__:Scraping page 13\n",
      "INFO:__main__:Scraping page 14\n",
      "INFO:__main__:Scraping page 15\n",
      "INFO:__main__:Scraping page 16\n",
      "INFO:__main__:Scraping page 17\n",
      "INFO:__main__:Scraping page 18\n",
      "INFO:__main__:Scraping page 19\n",
      "INFO:__main__:Scraping page 20\n",
      "INFO:__main__:Scraping page 21\n",
      "INFO:__main__:Scraping page 22\n",
      "INFO:__main__:Scraping page 23\n",
      "INFO:__main__:Scraping page 24\n",
      "INFO:__main__:Scraping page 25\n",
      "INFO:__main__:Finished scraping page 11\n",
      "INFO:__main__:Scraping page 26\n",
      "INFO:__main__:Finished scraping page 3\n",
      "INFO:__main__:Scraping page 27\n",
      "INFO:__main__:Finished scraping page 10\n",
      "INFO:__main__:Scraping page 28\n",
      "INFO:__main__:Finished scraping page 9\n",
      "INFO:__main__:Finished scraping page 13\n",
      "INFO:__main__:Scraping page 29\n",
      "INFO:__main__:Finished scraping page 17\n",
      "INFO:__main__:Finished scraping page 16\n",
      "INFO:__main__:Scraping page 30\n",
      "INFO:__main__:Scraping page 31\n",
      "INFO:__main__:Scraping page 32\n",
      "INFO:__main__:Finished scraping page 18\n",
      "INFO:__main__:Finished scraping page 20\n",
      "INFO:__main__:Finished scraping page 2\n",
      "INFO:__main__:Finished scraping page 25\n",
      "INFO:__main__:Finished scraping page 23\n",
      "INFO:__main__:Finished scraping page 5\n",
      "INFO:__main__:Finished scraping page 7\n",
      "INFO:__main__:Scraping page 39\n",
      "INFO:__main__:Finished scraping page 12\n",
      "INFO:__main__:Finished scraping page 1\n",
      "INFO:__main__:Finished scraping page 19\n",
      "INFO:__main__:Finished scraping page 21\n",
      "INFO:__main__:Scraping page 43\n",
      "INFO:__main__:Finished scraping page 22\n",
      "INFO:__main__:Finished scraping page 6\n",
      "INFO:__main__:Scraping page 33\n",
      "INFO:__main__:Scraping page 34\n",
      "INFO:__main__:Scraping page 35\n",
      "INFO:__main__:Scraping page 36\n",
      "INFO:__main__:Scraping page 37\n",
      "INFO:__main__:Finished scraping page 29\n",
      "INFO:__main__:Scraping page 38\n",
      "INFO:__main__:Finished scraping page 27\n",
      "INFO:__main__:Scraping page 47\n",
      "INFO:__main__:Scraping page 40\n",
      "INFO:__main__:Finished scraping page 15\n",
      "INFO:__main__:Scraping page 41\n",
      "INFO:__main__:Scraping page 42\n",
      "INFO:__main__:Finished scraping page 28\n",
      "INFO:__main__:Finished scraping page 24\n",
      "INFO:__main__:Scraping page 44\n",
      "INFO:__main__:Finished scraping page 4\n",
      "INFO:__main__:Scraping page 45\n",
      "INFO:__main__:Scraping page 46\n",
      "INFO:__main__:Finished scraping page 26\n",
      "INFO:__main__:Finished scraping page 32\n",
      "INFO:__main__:Finished scraping page 31\n",
      "INFO:__main__:Scraping page 54\n",
      "INFO:__main__:Scraping page 48\n",
      "INFO:__main__:Scraping page 49\n",
      "INFO:__main__:Scraping page 50\n",
      "INFO:__main__:Scraping page 51\n",
      "INFO:__main__:Finished scraping page 39\n",
      "INFO:__main__:Scraping page 52\n",
      "INFO:__main__:Scraping page 53\n",
      "INFO:__main__:Finished scraping page 30\n",
      "INFO:__main__:Scraping page 55\n",
      "INFO:__main__:Scraping page 56\n",
      "INFO:__main__:Finished scraping page 33\n",
      "INFO:__main__:Scraping page 57\n",
      "INFO:__main__:Finished scraping page 35\n",
      "INFO:__main__:Scraping page 58\n",
      "INFO:__main__:Finished scraping page 34\n",
      "INFO:__main__:Scraping page 59\n",
      "INFO:__main__:Finished scraping page 36\n",
      "INFO:__main__:Scraping page 60\n",
      "INFO:__main__:Finished scraping page 43\n",
      "INFO:__main__:Scraping page 61\n",
      "INFO:__main__:Finished scraping page 38\n",
      "INFO:__main__:Scraping page 62\n",
      "INFO:__main__:Finished scraping page 42\n",
      "INFO:__main__:Finished scraping page 56\n",
      "INFO:__main__:Finished scraping page 53\n",
      "INFO:__main__:Scraping page 63\n",
      "INFO:__main__:Finished scraping page 57\n",
      "INFO:__main__:Scraping page 64\n",
      "INFO:__main__:Finished scraping page 46\n",
      "INFO:__main__:Finished scraping page 54\n",
      "INFO:__main__:Scraping page 68\n",
      "INFO:__main__:Finished scraping page 14\n",
      "INFO:__main__:Finished scraping page 48\n",
      "INFO:__main__:Scraping page 70\n",
      "INFO:__main__:Finished scraping page 52\n",
      "INFO:__main__:Scraping page 71\n",
      "INFO:__main__:Finished scraping page 41\n",
      "INFO:__main__:Finished scraping page 59\n",
      "INFO:__main__:Finished scraping page 40\n",
      "INFO:__main__:Scraping page 66\n",
      "INFO:__main__:Finished scraping page 50\n",
      "INFO:__main__:Finished scraping page 37\n",
      "INFO:__main__:Finished scraping page 55\n",
      "INFO:__main__:Scraping page 67\n",
      "INFO:__main__:Finished scraping page 45\n",
      "INFO:__main__:Finished scraping page 61\n",
      "INFO:__main__:Finished scraping page 60\n",
      "INFO:__main__:Scraping page 80\n",
      "INFO:__main__:Finished scraping page 49\n",
      "INFO:__main__:Finished scraping page 58\n",
      "INFO:__main__:Scraping page 69\n",
      "INFO:__main__:Finished scraping page 44\n",
      "INFO:__main__:Scraping page 83\n",
      "INFO:__main__:Finished scraping page 47\n",
      "INFO:__main__:Scraping page 84\n",
      "INFO:__main__:Scraping page 73\n",
      "INFO:__main__:Scraping page 74\n",
      "INFO:__main__:Scraping page 75\n",
      "INFO:__main__:Finished scraping page 63\n",
      "INFO:__main__:Finished scraping page 62\n",
      "INFO:__main__:Scraping page 76\n",
      "INFO:__main__:Scraping page 77\n",
      "INFO:__main__:Scraping page 78\n",
      "INFO:__main__:Scraping page 79\n",
      "INFO:__main__:Finished scraping page 51\n",
      "INFO:__main__:Scraping page 81\n",
      "INFO:__main__:Scraping page 82\n",
      "INFO:__main__:Scraping page 65\n",
      "INFO:__main__:Scraping page 72\n",
      "INFO:__main__:Scraping page 85\n",
      "INFO:__main__:Scraping page 86\n",
      "INFO:__main__:Scraping page 87\n",
      "INFO:__main__:Finished scraping page 64\n",
      "INFO:__main__:Scraping page 88\n",
      "INFO:__main__:Finished scraping page 70\n",
      "INFO:__main__:Scraping page 89\n",
      "INFO:__main__:Finished scraping page 68\n",
      "INFO:__main__:Finished scraping page 71\n",
      "INFO:__main__:Scraping page 90\n",
      "INFO:__main__:Scraping page 91\n",
      "INFO:__main__:Finished scraping page 83\n",
      "INFO:__main__:Finished scraping page 69\n",
      "INFO:__main__:Finished scraping page 86\n",
      "INFO:__main__:Finished scraping page 79\n",
      "INFO:__main__:Finished scraping page 67\n",
      "INFO:__main__:Scraping page 96\n",
      "INFO:__main__:Finished scraping page 87\n",
      "INFO:__main__:Scraping page 92\n",
      "INFO:__main__:Scraping page 93\n",
      "INFO:__main__:Finished scraping page 65\n",
      "INFO:__main__:Finished scraping page 81\n",
      "INFO:__main__:Scraping page 99\n",
      "INFO:__main__:Finished scraping page 85\n",
      "INFO:__main__:Finished scraping page 77\n",
      "INFO:__main__:Scraping page 101\n",
      "INFO:__main__:Finished scraping page 78\n",
      "INFO:__main__:Scraping page 95\n",
      "INFO:__main__:Finished scraping page 73\n",
      "INFO:__main__:Finished scraping page 82\n",
      "INFO:__main__:Finished scraping page 76\n",
      "INFO:__main__:Finished scraping page 72\n",
      "INFO:__main__:Finished scraping page 74\n",
      "INFO:__main__:Scraping page 107\n",
      "INFO:__main__:Scraping page 97\n",
      "INFO:__main__:Finished scraping page 80\n",
      "INFO:__main__:Finished scraping page 84\n",
      "INFO:__main__:Finished scraping page 8\n",
      "INFO:__main__:Finished scraping page 89\n",
      "INFO:__main__:Scraping page 98\n",
      "INFO:__main__:Scraping page 94\n",
      "INFO:__main__:Scraping page 100\n",
      "INFO:__main__:Finished scraping page 66\n",
      "INFO:__main__:Finished scraping page 91\n",
      "INFO:__main__:Finished scraping page 90\n",
      "INFO:__main__:Scraping page 102\n",
      "INFO:__main__:Scraping page 103\n",
      "INFO:__main__:Scraping page 104\n",
      "INFO:__main__:Scraping page 105\n",
      "INFO:__main__:Scraping page 106\n",
      "INFO:__main__:Finished scraping page 75\n",
      "INFO:__main__:Scraping page 115\n",
      "INFO:__main__:Finished scraping page 96\n",
      "INFO:__main__:Scraping page 109\n",
      "INFO:__main__:Scraping page 110\n",
      "INFO:__main__:Scraping page 111\n",
      "INFO:__main__:Scraping page 112\n",
      "INFO:__main__:Scraping page 113\n",
      "INFO:__main__:Scraping page 114\n",
      "INFO:__main__:Scraping page 108\n",
      "INFO:__main__:Scraping page 116\n",
      "INFO:__main__:Finished scraping page 93\n",
      "INFO:__main__:Finished scraping page 92\n",
      "INFO:__main__:Finished scraping page 88\n",
      "INFO:__main__:Scraping page 119\n",
      "INFO:__main__:Scraping page 118\n",
      "INFO:__main__:Scraping page 117\n",
      "INFO:__main__:Finished scraping page 99\n",
      "INFO:__main__:Scraping page 120\n",
      "INFO:__main__:Finished scraping page 108\n",
      "INFO:__main__:Scraping page 121\n",
      "INFO:__main__:Finished scraping page 111\n",
      "INFO:__main__:Scraping page 122\n",
      "INFO:__main__:Finished scraping page 110\n",
      "INFO:__main__:Finished scraping page 113\n",
      "INFO:__main__:Scraping page 124\n",
      "INFO:__main__:Finished scraping page 114\n",
      "INFO:__main__:Finished scraping page 98\n",
      "INFO:__main__:Finished scraping page 103\n",
      "INFO:__main__:Finished scraping page 112\n",
      "INFO:__main__:Finished scraping page 97\n",
      "INFO:__main__:Scraping page 123\n",
      "INFO:__main__:Finished scraping page 115\n",
      "INFO:__main__:Finished scraping page 109\n",
      "INFO:__main__:Finished scraping page 101\n",
      "INFO:__main__:Finished scraping page 107\n",
      "INFO:__main__:Finished scraping page 102\n",
      "INFO:__main__:Finished scraping page 106\n",
      "INFO:__main__:Finished scraping page 104\n",
      "INFO:__main__:Finished scraping page 94\n",
      "INFO:__main__:Finished scraping page 105\n",
      "INFO:__main__:Finished scraping page 119\n",
      "INFO:__main__:Finished scraping page 120\n",
      "INFO:__main__:Finished scraping page 117\n",
      "INFO:__main__:Finished scraping page 118\n",
      "INFO:__main__:Finished scraping page 121\n",
      "INFO:__main__:Finished scraping page 122\n",
      "INFO:__main__:Finished scraping page 95\n",
      "INFO:__main__:Finished scraping page 124\n",
      "INFO:__main__:Finished scraping page 123\n",
      "INFO:__main__:Finished scraping page 116\n",
      "INFO:__main__:Finished scraping page 100\n",
      "INFO:__main__:Watch scraping program completed successfully, scraping 14875 watches in 0 minutes and 49 seconds!\n"
     ]
    }
   ],
   "source": [
    "import concurrent.futures\n",
    "import logging\n",
    "\n",
    "import bs4\n",
    "import pandas as pd\n",
    "import requests\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "BASE_URL = \"https://www.chrono24.com/\"\n",
    "# BASE_ENDPOINT = \"rolex/index.htm?man=rolex&pageSize=120&resultview=list&showpage=\"\n",
    "# https://www.chrono24.com/patekphilippe/index.htm?man=patekphilippe&pageSize=60&showpage=1\n",
    "BASE_ENDPOINT = \"patekphilippe/index.htm?man=patekphilippe&pageSize=120&resultview=list&showpage=\"\n",
    "\n",
    "\n",
    "def _get_soup(url: str) -> bs4.BeautifulSoup:\n",
    "    HEADERS = {\n",
    "        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/119.0.0.0 Safari/537.36\"\n",
    "    }\n",
    "    with requests.get(url=url, headers=HEADERS) as response:\n",
    "        response.raise_for_status()\n",
    "        return bs4.BeautifulSoup(markup=response.text, features=\"html.parser\")\n",
    "\n",
    "\n",
    "\n",
    "def _get_number_of_pages_to_scrape() -> int:\n",
    "    soup = _get_soup(url=f\"{BASE_URL}{BASE_ENDPOINT}\")\n",
    "    pagination = soup.find(name=\"ul\", attrs={\"class\": \"pagination\"})\n",
    "    page_number_selectors = [a_tag.get_text(strip=True) for a_tag in pagination.find_all(\"a\")]\n",
    "    return max([int(num) for num in page_number_selectors if num.isnumeric()])\n",
    "\n",
    "\n",
    "def _get_page_listings(soup: bs4.BeautifulSoup) -> list[bs4.element.Tag]:\n",
    "    return soup.find(name=\"div\", attrs={\"id\": \"wt-watches\"}).find_all(\n",
    "        name=\"div\", attrs={\"class\": \"media-flex-body d-flex flex-column justify-content-between p-y-2 p-y-sm-0\"}\n",
    "    )\n",
    "\n",
    "\n",
    "def _get_listing_name(listing: bs4.element.Tag) -> str:\n",
    "    return listing.find(name=\"div\", attrs={\"class\": \"text-sm text-sm-xlg text-bold text-ellipsis\"}).get_text(strip=True)\n",
    "\n",
    "\n",
    "def _get_listing_info(listing: bs4.element.Tag) -> dict[str, str]:\n",
    "    info_table = listing.find(name=\"div\", attrs={\"class\": \"d-none d-sm-flex flex-wrap m-b-3\"})\n",
    "    info_items = [\n",
    "        tuple(info.get_text(strip=True).split(\":\", maxsplit=1)) for info in info_table.find_all(\"div\", {\"class\": \"w-50\"})\n",
    "    ]\n",
    "    return dict(info_items)\n",
    "\n",
    "\n",
    "def _get_listing_price(listing: bs4.element.Tag) -> str:\n",
    "    return listing.find(\"div\", {\"class\": \"text-md text-sm-xlg text-bold\"}).get_text(strip=True)\n",
    "\n",
    "\n",
    "def _scrape_page(page_num: int) -> list[dict[str, str]]:\n",
    "    logger.info(f\"Scraping page {page_num}\")\n",
    "    soup = _get_soup(url=f\"{BASE_URL}{BASE_ENDPOINT}{page_num}\")\n",
    "    result = [\n",
    "        {\"name\": _get_listing_name(listing=listing)}\n",
    "        | _get_listing_info(listing=listing)\n",
    "        | {\"price\": _get_listing_price(listing=listing)}\n",
    "        for listing in _get_page_listings(soup=soup)\n",
    "    ]\n",
    "    logger.info(f\"Finished scraping page {page_num}\")\n",
    "    return result\n",
    "\n",
    "\n",
    "def watch_scraping_program(max_threading_workers: int = 25) -> None:\n",
    "    start_time = pd.Timestamp.now()\n",
    "    logger.info(f\"Starting watch scraping program as of {pd.Timestamp.now().strftime('%D %T')} with {max_threading_workers=}\")\n",
    "    num_pages = _get_number_of_pages_to_scrape()\n",
    "    logger.info(f\"Found {num_pages} pages to scrape from {BASE_URL}\")\n",
    "\n",
    "    watches = list()\n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=max_threading_workers) as executor:\n",
    "        for result in executor.map(_scrape_page, range(1, num_pages + 1)):\n",
    "            watches += result\n",
    "\n",
    "    pd.DataFrame(watches).to_csv(f\"raw_data.csv\", index=False)\n",
    "    timedelta = (pd.Timestamp.now() - start_time).seconds\n",
    "    logger.info(\n",
    "        f\"Watch scraping program completed successfully, scraping {len(watches)} watches in \"\n",
    "        f\"{int(timedelta/60)} minutes and {timedelta % 60} seconds!\"\n",
    "    )\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    watch_scraping_program()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
